{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7682e0",
   "metadata": {},
   "source": [
    "### 카메라에서 실시간으로 영상을 캡처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2301af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2  \n",
    "\n",
    "# 웹캠 연결 및 비디오 캡처 객체 생성 (0은 기본 카메라를 나타냄)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# 웹캠이 열려있는 동안 계속 반복\n",
    "while True:\n",
    "    # 첫 번째 반환 값은 프레임이 정상적으로 읽혔는지 여부\n",
    "    # 두 번째 반환 값은 읽어온 프레임\n",
    "    check, frame = cam.read()\n",
    "\n",
    "    # 읽어온 프레임을 화면에 출력\n",
    "    cv2.imshow(\"webcam\", frame)\n",
    "\n",
    "    # 키보드 입력을 확인합니다. 입력이 있으면 루프를 종료\n",
    "    key = cv2.waitKey(1)\n",
    "    if key != -1:\n",
    "        break\n",
    "\n",
    "# 웹캠 연결을 종료하고, 모든 OpenCV 창을 닫기\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cb856",
   "metadata": {},
   "source": [
    "## 웹캠으로 YOLO v5 실행하기(COCO dataset)\n",
    "\n",
    "- https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bca8a1",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870c22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangwoo\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
    "\"\"\"\n",
    "Run inference on images, videos, directories, streams, etc.\n",
    "\n",
    "Usage - sources:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt --source 0              # webcam\n",
    "                                                             img.jpg        # image\n",
    "                                                             vid.mp4        # video\n",
    "                                                             path/          # directory\n",
    "                                                             path/*.jpg     # glob\n",
    "                                                             'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                                                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "\n",
    "Usage - formats:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt                 # PyTorch\n",
    "                                         yolov5s.torchscript        # TorchScript\n",
    "                                         yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn\n",
    "                                         yolov5s.xml                # OpenVINO\n",
    "                                         yolov5s.engine             # TensorRT\n",
    "                                         yolov5s.mlmodel            # CoreML (macOS-only)\n",
    "                                         yolov5s_saved_model        # TensorFlow SavedModel\n",
    "                                         yolov5s.pb                 # TensorFlow GraphDef\n",
    "                                         yolov5s.tflite             # TensorFlow Lite\n",
    "                                         yolov5s_edgetpu.tflite     # TensorFlow Edge TPU\n",
    "\"\"\"\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# FILE = Path(__file__).resolve()\n",
    "# ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "# if str(ROOT) not in sys.path:\n",
    "#     sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "# ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "from utils.augmentations import letterbox\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d26c0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 2. 실시간 예측하기(일반카메라)\n",
    "\n",
    "#### 객체 검출 및 분류를 수행하기 전에 필요한 여러 설정값들을 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b9ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsz = (640, 640)  # 이미지의 크기 (너비, 높이)\n",
    "weights = \"./yolov5m.pt\"  # 학습된 모델의 가중치 파일 경로\n",
    "device = ''  # 연산에 사용할 장치 (비워 둘 경우, 자동으로 GPU 또는 CPU를 선택)\n",
    "visualize = False  # 시각화 옵션\n",
    "augment = False  # 데이터 증강 옵션\n",
    "conf_thres = 0.25  # 객체 탐지에 사용할 최소 신뢰도 임계값\n",
    "iou_thres = 0.45  # NMS를 위한 IoU(Intersection over Union) 임계값\n",
    "classes = [i for i in range(1000)]  # 탐지할 클래스 인덱스 목록\n",
    "agnostic_nms = False  # 클래스에 관계없이 NMS를 적용할지 여부\n",
    "max_det = 1000  # 한 이미지에서 탐지할 수 있는 최대 객체 수\n",
    "webcam = False  # 웹캠을 사용하여 실시간 객체 탐지를 수행할지 여부\n",
    "view_img = True  # 탐지 결과를 화면에 표시할지 여부\n",
    "save_crop = False  # 탐지된 객체를 자른 이미지로 저장할지 여부\n",
    "line_thickness = 5  # 객체 경계 상자의 선 두께\n",
    "save_txt = False  # 탐지 결과를 텍스트 파일로 저장할지 여부\n",
    "hide_labels = False  # 탐지된 객체의 레이블을 숨길지 여부\n",
    "hide_conf = False  # 탐지된 객체의 신뢰도를 숨길지 여부\n",
    "dnn = False  # DNN 모듈을 사용할지 여부\n",
    "data = False  # 데이터셋을 사용할지 여부\n",
    "half = False  # 반정밀도(FP16) 계산을 사용할지 여부\n",
    "save_img = 'video'  # 이미지 또는 비디오를 저장할지 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baeccf",
   "metadata": {},
   "source": [
    "### 사전 학습된 가중치를 불러와 객체 검출 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e73f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-153-gff6a9ac Python-3.8.16 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# 웹캠에서 프레임 캡처\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     ret_val, img0 \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 배치 크기\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     vid_path, vid_writer \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m bs, [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m bs\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "device = select_device(device)\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half) # weights에 경로 넣기\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size(imgsz, s=stride)  # 이미지 크기 확인 및 업데이트\n",
    "\n",
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # 웹캠에서 프레임 캡처\n",
    "    ret_val, img0 = cap.read()\n",
    "\n",
    "    bs = 1  # 배치 크기\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # 워밍업\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "\n",
    "    # 패딩된 리사이즈\n",
    "    img = letterbox(img0, imgsz, stride=stride, auto=pt)[0]\n",
    "\n",
    "    # 변환\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    im = img.copy()\n",
    "    im0s = img0.copy()\n",
    "\n",
    "    t1 = time_sync()\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]  # 배치 차원 확장\n",
    "    t2 = time_sync()\n",
    "    dt[0] += t2 - t1\n",
    "\n",
    "    # 추론\n",
    "    visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "    pred = model(im, augment=augment, visualize=visualize)\n",
    "    t3 = time_sync()\n",
    "    dt[1] += t3 - t2\n",
    "\n",
    "    # NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "    dt[2] += time_sync() - t3\n",
    "\n",
    "    # 예측 결과 처리\n",
    "    for i, det in enumerate(pred):  # 이미지 당\n",
    "        seen += 1\n",
    "        if webcam:  # 배치 크기 >= 1\n",
    "            p, im0, frame = None, im0s[i].copy(), None\n",
    "            s += f'{i}: '\n",
    "        else:\n",
    "            p, im0, frame = None, im0s.copy(), None\n",
    "        \n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # 정규화 획득 whwh\n",
    "        imc = im0.copy() if save_crop else im0  # save_crop 용\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "        if len(det):\n",
    "            # 박스 좌표를 img_size에서 im0 크기로 변환\n",
    "            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # 결과 출력\n",
    "            for c in det[:, -1].unique():\n",
    "                n = (det[:, -1] == c).sum()  # 클래스별 탐지 수\n",
    "                # s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # 문자열 추가\n",
    "\n",
    "            # 결과 저장\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                if save_txt:  # 파일에 저장\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # 정규화된 xywh\n",
    "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # 라벨 형식\n",
    "                    with open(f'{txt_path}.txt', 'a') as f:\n",
    "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                if save_img or save_crop or view_img:  # 이미지에 bbox 추가\n",
    "                    c = int(cls)  # 정수 클래스\n",
    "                    label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                    annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                if save_crop:\n",
    "                    save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "        # 결과 스트리밍\n",
    "        im0 = annotator.result()\n",
    "        if view_img:\n",
    "            cv2.imshow(str(p), im0)\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            if key != -1:\n",
    "                break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
