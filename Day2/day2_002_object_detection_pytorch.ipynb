{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7682e0",
   "metadata": {},
   "source": [
    "### ì¹´ë©”ë¼ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ìƒì„ ìº¡ì²˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2301af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2  \n",
    "\n",
    "# ì›¹ìº  ì—°ê²° ë° ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„± (0ì€ ê¸°ë³¸ ì¹´ë©”ë¼ë¥¼ ë‚˜íƒ€ëƒ„)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# ì›¹ìº ì´ ì—´ë ¤ìˆëŠ” ë™ì•ˆ ê³„ì† ë°˜ë³µ\n",
    "while True:\n",
    "    # ì²« ë²ˆì§¸ ë°˜í™˜ ê°’ì€ í”„ë ˆì„ì´ ì •ìƒì ìœ¼ë¡œ ì½í˜”ëŠ”ì§€ ì—¬ë¶€\n",
    "    # ë‘ ë²ˆì§¸ ë°˜í™˜ ê°’ì€ ì½ì–´ì˜¨ í”„ë ˆì„\n",
    "    check, frame = cam.read()\n",
    "\n",
    "    # ì½ì–´ì˜¨ í”„ë ˆì„ì„ í™”ë©´ì— ì¶œë ¥\n",
    "    cv2.imshow(\"webcam\", frame)\n",
    "\n",
    "    # í‚¤ë³´ë“œ ì…ë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤. ì…ë ¥ì´ ìˆìœ¼ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œ\n",
    "    key = cv2.waitKey(1)\n",
    "    if key != -1:\n",
    "        break\n",
    "\n",
    "# ì›¹ìº  ì—°ê²°ì„ ì¢…ë£Œí•˜ê³ , ëª¨ë“  OpenCV ì°½ì„ ë‹«ê¸°\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cb856",
   "metadata": {},
   "source": [
    "## ì›¹ìº ìœ¼ë¡œ YOLO v5 ì‹¤í–‰í•˜ê¸°(COCO dataset)\n",
    "\n",
    "- https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bca8a1",
   "metadata": {},
   "source": [
    "### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870c22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangwoo\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license\n",
    "\"\"\"\n",
    "Run inference on images, videos, directories, streams, etc.\n",
    "\n",
    "Usage - sources:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt --source 0              # webcam\n",
    "                                                             img.jpg        # image\n",
    "                                                             vid.mp4        # video\n",
    "                                                             path/          # directory\n",
    "                                                             path/*.jpg     # glob\n",
    "                                                             'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                                                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "\n",
    "Usage - formats:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt                 # PyTorch\n",
    "                                         yolov5s.torchscript        # TorchScript\n",
    "                                         yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn\n",
    "                                         yolov5s.xml                # OpenVINO\n",
    "                                         yolov5s.engine             # TensorRT\n",
    "                                         yolov5s.mlmodel            # CoreML (macOS-only)\n",
    "                                         yolov5s_saved_model        # TensorFlow SavedModel\n",
    "                                         yolov5s.pb                 # TensorFlow GraphDef\n",
    "                                         yolov5s.tflite             # TensorFlow Lite\n",
    "                                         yolov5s_edgetpu.tflite     # TensorFlow Edge TPU\n",
    "\"\"\"\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# FILE = Path(__file__).resolve()\n",
    "# ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "# if str(ROOT) not in sys.path:\n",
    "#     sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "# ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "from utils.augmentations import letterbox\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d26c0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 2. ì‹¤ì‹œê°„ ì˜ˆì¸¡í•˜ê¸°(ì¼ë°˜ì¹´ë©”ë¼)\n",
    "\n",
    "#### ê°ì²´ ê²€ì¶œ ë° ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì— í•„ìš”í•œ ì—¬ëŸ¬ ì„¤ì •ê°’ë“¤ì„ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b9ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsz = (640, 640)  # ì´ë¯¸ì§€ì˜ í¬ê¸° (ë„ˆë¹„, ë†’ì´)\n",
    "weights = \"./yolov5m.pt\"  # í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ\n",
    "device = ''  # ì—°ì‚°ì— ì‚¬ìš©í•  ì¥ì¹˜ (ë¹„ì›Œ ë‘˜ ê²½ìš°, ìë™ìœ¼ë¡œ GPU ë˜ëŠ” CPUë¥¼ ì„ íƒ)\n",
    "visualize = False  # ì‹œê°í™” ì˜µì…˜\n",
    "augment = False  # ë°ì´í„° ì¦ê°• ì˜µì…˜\n",
    "conf_thres = 0.25  # ê°ì²´ íƒì§€ì— ì‚¬ìš©í•  ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "iou_thres = 0.45  # NMSë¥¼ ìœ„í•œ IoU(Intersection over Union) ì„ê³„ê°’\n",
    "classes = [i for i in range(1000)]  # íƒì§€í•  í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ëª©ë¡\n",
    "agnostic_nms = False  # í´ë˜ìŠ¤ì— ê´€ê³„ì—†ì´ NMSë¥¼ ì ìš©í• ì§€ ì—¬ë¶€\n",
    "max_det = 1000  # í•œ ì´ë¯¸ì§€ì—ì„œ íƒì§€í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ê°ì²´ ìˆ˜\n",
    "webcam = False  # ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í• ì§€ ì—¬ë¶€\n",
    "view_img = True  # íƒì§€ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí• ì§€ ì—¬ë¶€\n",
    "save_crop = False  # íƒì§€ëœ ê°ì²´ë¥¼ ìë¥¸ ì´ë¯¸ì§€ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€\n",
    "line_thickness = 5  # ê°ì²´ ê²½ê³„ ìƒìì˜ ì„  ë‘ê»˜\n",
    "save_txt = False  # íƒì§€ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€\n",
    "hide_labels = False  # íƒì§€ëœ ê°ì²´ì˜ ë ˆì´ë¸”ì„ ìˆ¨ê¸¸ì§€ ì—¬ë¶€\n",
    "hide_conf = False  # íƒì§€ëœ ê°ì²´ì˜ ì‹ ë¢°ë„ë¥¼ ìˆ¨ê¸¸ì§€ ì—¬ë¶€\n",
    "dnn = False  # DNN ëª¨ë“ˆì„ ì‚¬ìš©í• ì§€ ì—¬ë¶€\n",
    "data = False  # ë°ì´í„°ì…‹ì„ ì‚¬ìš©í• ì§€ ì—¬ë¶€\n",
    "half = False  # ë°˜ì •ë°€ë„(FP16) ê³„ì‚°ì„ ì‚¬ìš©í• ì§€ ì—¬ë¶€\n",
    "save_img = 'video'  # ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ì €ì¥í• ì§€ ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baeccf",
   "metadata": {},
   "source": [
    "### ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì™€ ê°ì²´ ê²€ì¶œ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e73f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-153-gff6a9ac Python-3.8.16 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# ì›¹ìº ì—ì„œ í”„ë ˆì„ ìº¡ì²˜\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     ret_val, img0 \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# ë°°ì¹˜ í¬ê¸°\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     vid_path, vid_writer \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m bs, [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m bs\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "device = select_device(device)\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half) # weightsì— ê²½ë¡œ ë„£ê¸°\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size(imgsz, s=stride)  # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ë° ì—…ë°ì´íŠ¸\n",
    "\n",
    "# ì›¹ìº  ì´ˆê¸°í™”\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # ì›¹ìº ì—ì„œ í”„ë ˆì„ ìº¡ì²˜\n",
    "    ret_val, img0 = cap.read()\n",
    "\n",
    "    bs = 1  # ë°°ì¹˜ í¬ê¸°\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # ì›Œë°ì—…\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "\n",
    "    # íŒ¨ë”©ëœ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    img = letterbox(img0, imgsz, stride=stride, auto=pt)[0]\n",
    "\n",
    "    # ë³€í™˜\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    im = img.copy()\n",
    "    im0s = img0.copy()\n",
    "\n",
    "    t1 = time_sync()\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]  # ë°°ì¹˜ ì°¨ì› í™•ì¥\n",
    "    t2 = time_sync()\n",
    "    dt[0] += t2 - t1\n",
    "\n",
    "    # ì¶”ë¡ \n",
    "    visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "    pred = model(im, augment=augment, visualize=visualize)\n",
    "    t3 = time_sync()\n",
    "    dt[1] += t3 - t2\n",
    "\n",
    "    # NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "    dt[2] += time_sync() - t3\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬\n",
    "    for i, det in enumerate(pred):  # ì´ë¯¸ì§€ ë‹¹\n",
    "        seen += 1\n",
    "        if webcam:  # ë°°ì¹˜ í¬ê¸° >= 1\n",
    "            p, im0, frame = None, im0s[i].copy(), None\n",
    "            s += f'{i}: '\n",
    "        else:\n",
    "            p, im0, frame = None, im0s.copy(), None\n",
    "        \n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # ì •ê·œí™” íšë“ whwh\n",
    "        imc = im0.copy() if save_crop else im0  # save_crop ìš©\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "        if len(det):\n",
    "            # ë°•ìŠ¤ ì¢Œí‘œë¥¼ img_sizeì—ì„œ im0 í¬ê¸°ë¡œ ë³€í™˜\n",
    "            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            for c in det[:, -1].unique():\n",
    "                n = (det[:, -1] == c).sum()  # í´ë˜ìŠ¤ë³„ íƒì§€ ìˆ˜\n",
    "                # s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # ë¬¸ìì—´ ì¶”ê°€\n",
    "\n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                if save_txt:  # íŒŒì¼ì— ì €ì¥\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # ì •ê·œí™”ëœ xywh\n",
    "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # ë¼ë²¨ í˜•ì‹\n",
    "                    with open(f'{txt_path}.txt', 'a') as f:\n",
    "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                if save_img or save_crop or view_img:  # ì´ë¯¸ì§€ì— bbox ì¶”ê°€\n",
    "                    c = int(cls)  # ì •ìˆ˜ í´ë˜ìŠ¤\n",
    "                    label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                    annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                if save_crop:\n",
    "                    save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "        # ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        im0 = annotator.result()\n",
    "        if view_img:\n",
    "            cv2.imshow(str(p), im0)\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            if key != -1:\n",
    "                break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
