{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0f1e1",
   "metadata": {},
   "source": [
    "### Created on 2023\n",
    "### @author: S.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc6961",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Pytorch\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142b47d",
   "metadata": {},
   "source": [
    "## CIFAR-10 데이터셋으로 이미지 분류 해보기 - MLP\n",
    "\n",
    "### 0. CIFAR-10 데이터\n",
    "\n",
    "CIFAR-10은 Canadian Institute For Advanced Research (CIAR)에서 만든 컴퓨터 비전용 데이터셋입니다. 이 데이터셋은 32x32 크기의 컬러 이미지를 10개의 클래스로 분류하는 문제를 다룹니다.\n",
    "\n",
    "CIFAR-10 데이터셋은 다음과 같은 10개의 클래스로 구성되어 있습니다.\n",
    "\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck\n",
    "\n",
    "데이터셋은 50,000개의 훈련 이미지와 10,000개의 테스트 이미지로 구성되어 있습니다. 각 이미지는 RGB 채널 값으로 이루어져 있고, 픽셀 값은 0~255의 범위를 가집니다.\n",
    "\n",
    "- https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "### 1. 학습에 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c01c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 시각화 관련 라이브러리 불러오기\n",
    "import PIL\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 딥러닝 관련 라이브러리인 pytorch 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor, Normalize, RandomCrop, RandomHorizontalFlip\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8b4ea",
   "metadata": {},
   "source": [
    "torch.cuda.device_count() 함수는 시스템에 연결된 GPU 장치의 수를 반환합니다. 반환값이 0인 경우, 시스템에 GPU가 없는 것입니다.\n",
    "\n",
    "torch.cuda.is_available() 함수는 PyTorch에서 CUDA (NVIDIA의 GPU를 사용하는 라이브러리)가 사용 가능한지 여부를 확인합니다. 이 함수는 True 또는 False 값을 반환합니다. GPU가 설정되어 있지 않은 경우, PyTorch는 CPU를 사용하여 연산을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c323fad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "\n",
    "# GPU가 설정되어 있는지 확인\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717e16d",
   "metadata": {},
   "source": [
    "### 2. CIFAR-10 데이터 불러오기 & 이미지 데이터 전처리\n",
    "\n",
    "#### 이미지 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfbc9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 데이터셋 전처리\n",
    "train_transform = transforms.Compose([\n",
    "    RandomCrop(32, padding=4),  # 4겹의 패딩 후 32x32의 크기로 이미지를 뽑아냄.\n",
    "    RandomHorizontalFlip(),     # 이미지가 주어진 확률(default = 0.5)로 가로로 뒤집음.\n",
    "    ToTensor(),                 # 0~255의 픽셀 값을 0과 1사이의 값으로 변환\n",
    "    \n",
    "    # 데이터를 -1과 1사이의 값으로 변경, (평균이 0.5 표준편차가 0.5인 데이터)\n",
    "    Normalize((0.5, 0.5, 0.5), # 채널 별 평균\n",
    "              (0.5, 0.5, 0.5)) # 채널 별 표준편차 값  \n",
    "    \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# pytorch에 내장되어 있는 CIFAR-10 데이터 셋 불러오기\n",
    "train_dataset = CIFAR10(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "test_dataset = CIFAR10(root=\"./data\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d893f6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomCrop(size=(32, 32), padding=4)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋의 전반적인 정보 확인\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d14b3b",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87d9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "# 모델 초기화\n",
    "model = DNN().cuda()#.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70560d05",
   "metadata": {},
   "source": [
    "### 4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f2f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 1.8015\n",
      "Epoch 2 - Training loss: 1.6279\n",
      "Epoch 3 - Training loss: 1.5549\n",
      "Epoch 4 - Training loss: 1.5121\n",
      "Epoch 5 - Training loss: 1.4665\n",
      "Epoch 6 - Training loss: 1.4416\n",
      "Epoch 7 - Training loss: 1.4146\n",
      "Epoch 8 - Training loss: 1.3956\n",
      "Epoch 9 - Training loss: 1.3755\n",
      "Epoch 10 - Training loss: 1.3623\n"
     ]
    }
   ],
   "source": [
    "# 손실함수, 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()#.to(device)\n",
    "        labels = labels.cuda()#.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images).cuda()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch {} - Training loss: {:.4f}\".format(epoch+1, running_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9ec45",
   "metadata": {},
   "source": [
    "### 5. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494df173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 49.71%\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.cuda()#.to(device)\n",
    "        labels = labels.cuda()#.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy on test set: {:.2f}%\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20de73",
   "metadata": {},
   "source": [
    "## CIFAR-10 데이터셋으로 이미지 분류 해보기 - CNN\n",
    "\n",
    "### 1. 학습에 필요한 라이브러리 불러오기 - 생략\n",
    "### 2. CIFAR-10 데이터 불러오기\n",
    "\n",
    "#### 이미지 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e5df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 데이터셋 전처리\n",
    "train_transform = transforms.Compose([\n",
    "    RandomCrop(32, padding=4),  # 4겹의 패딩 후 32x32의 크기로 이미지를 뽑아냄.\n",
    "    RandomHorizontalFlip(),     # 이미지가 주어진 확률(default = 0.5)로 가로로 뒤집음.\n",
    "    ToTensor(),                 # 0~255의 픽셀 값을 0과 1사이의 값으로 변환\n",
    "    \n",
    "    # 데이터를 -1과 1사이의 값으로 변경, (평균이 0.5 표준편차가 0.5인 데이터)\n",
    "    Normalize((0.5, 0.5, 0.5), # 채널 별 평균\n",
    "              (0.5, 0.5, 0.5)) # 채널 별 표준편차 값  \n",
    "    \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# pytorch에 내장되어 있는 CIFAR-10 데이터 셋 불러오기\n",
    "train_dataset = CIFAR10(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "test_dataset = CIFAR10(root=\"./data\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637855c",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a789b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * 4 * 256, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 4 * 4 * 256)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNN().cuda()#.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679d986",
   "metadata": {},
   "source": [
    "### 4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28462cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangwoo\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 1.2261\n",
      "Epoch 2 - Training loss: 0.8708\n",
      "Epoch 3 - Training loss: 0.7405\n",
      "Epoch 4 - Training loss: 0.6614\n",
      "Epoch 5 - Training loss: 0.6050\n",
      "Epoch 6 - Training loss: 0.5643\n",
      "Epoch 7 - Training loss: 0.5181\n",
      "Epoch 8 - Training loss: 0.4883\n",
      "Epoch 9 - Training loss: 0.4579\n",
      "Epoch 10 - Training loss: 0.4304\n"
     ]
    }
   ],
   "source": [
    "# 손실함수, 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()#.to(device)\n",
    "        labels = labels.cuda()#.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images).cuda()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch {} - Training loss: {:.4f}\".format(epoch+1, running_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958b9d9",
   "metadata": {},
   "source": [
    "### 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a1eb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 83.79%\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "correct = 0\n",
    "total = 0\n",
    "predicted_all = []\n",
    "y_true_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.cuda()#.to(device)\n",
    "        labels = labels.cuda()#.to(device)\n",
    "\n",
    "        outputs = model(images).cuda()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        predicted_all = predicted_all + list(predicted)\n",
    "        y_true_all = y_true_all + list(labels)\n",
    "        \n",
    "print(\"Accuracy on test set: {:.2f}%\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef9e29",
   "metadata": {},
   "source": [
    "## 실제로 잘 맞췄는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19229267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 라벨 값 확인\n",
    "len(predicted_all), len(y_true_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28778896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(80,52.8;496x369.6)\n",
      "실제 라벨 값:  tensor(7, device='cuda:0') \n",
      "예측 라벨 값: tensor(7, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 13\n",
    "batch_size = 128\n",
    "\n",
    "val_1, val_2 = divmod(n, batch_size)\n",
    "\n",
    "img = next(iter(test_loader))[val_1].numpy()\n",
    "\n",
    "print(plt.imshow(np.transpose(img[val_2], (1, 2, 0))))\n",
    "print(\"실제 라벨 값: \", y_true_all[n], \"\\n예측 라벨 값:\", predicted_all[n])# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
