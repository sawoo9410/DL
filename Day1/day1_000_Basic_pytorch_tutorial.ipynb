{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f864d08d",
   "metadata": {},
   "source": [
    "### Created on 2023\n",
    "### @author: S.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671e068",
   "metadata": {},
   "source": [
    "PyTorch는 파이썬 기반의 오픈소스 머신러닝 프레임워크로, 텐서 연산 및 그래프 생성, 자동 미분 등을 지원하여 딥러닝 모델의 학습 및 추론을 쉽게 구현할 수 있습니다. 이번에는 PyTorch 공식 홈페이지에서 제공하는 튜토리얼 중 하나인 \"예제로 배우는 PyTorch\"를 기반으로 PyTorch의 기초적인 개념과 사용 방법을 설명하겠습니다.\n",
    "\n",
    "## 데이터셋 다운로드 및 전처리\n",
    "\n",
    "첫 번째로, PyTorch에서 제공하는 torchvision 패키지를 이용해 데이터셋을 다운로드하고 전처리합니다. 이 예제에서는 MNIST 숫자 이미지 데이터셋을 사용합니다. torchvision.transforms.Compose를 사용해 다양한 전처리 기능을 조합할 수 있습니다. 이 예제에서는 이미지를 tensor로 변환하고, normalization을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b45be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24920\\705755252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 데이터셋 다운로드 및 전처리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터셋 다운로드 및 전처리\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc210d",
   "metadata": {},
   "source": [
    "위 코드에서는 torchvision.transforms.Compose를 사용하여 데이터 전처리 기능을 조합합니다. 먼저 ToTensor() 함수를 사용하여 이미지를 tensor로 변환하고, Normalize() 함수를 사용하여 이미지의 pixel 값을 -1~1 범위로 정규화합니다. MNIST 데이터셋을 다운로드하고, train=True인 경우 trainset으로, train=False인 경우 testset으로 데이터를 로드합니다. 그리고 DataLoader를 사용하여 데이터를 배치 단위로 로드합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef697352",
   "metadata": {},
   "source": [
    "## 신경망 모델 정의\n",
    "\n",
    "두 번째로, PyTorch에서는 신경망 모델을 정의하기 위해 nn.Module 클래스를 상속받아 모델을 정의합니다. 이 예제에서는 Convolutional Neural Network (CNN)을 사용합니다. nn.Conv2d, nn.MaxPool2d 등의 함수를 사용하여 CNN 레이어를 생성합니다. forward 함수를 정의하여 입력을 모델에 전달하면 출력을 반환하도록 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc07650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc2af3",
   "metadata": {},
   "source": [
    "## 데이터 로드 및 학습\n",
    "\n",
    "세 번째로, 모델을 학습시키기 위해 데이터셋을 준비하고 모델을 학습시킵니다. 이 예제에서는 MNIST 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ba681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape(-1, 28*28)\n",
    "\n",
    "        # forward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        loss.backward()\n",
    "        optimizer.step() # optimize\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c49b2a",
   "metadata": {},
   "source": [
    "위 코드에서 nn.CrossEntropyLoss()를 사용하여 분류 문제에서 사용하는 교차 엔트로피 손실 함수를 정의합니다. optim.SGD를 사용하여 Stochastic Gradient Descent (SGD) 최적화 알고리즘을 사용합니다. lr은 학습률을, momentum은 SGD에 사용하는 모멘텀 값을 설정합니다.\n",
    "\n",
    "학습 과정에서는 trainloader에서 배치를 하나씩 가져옵니다. inputs와 labels를 가져온 다음, optimizer.zero_grad()를 사용하여 가중치의 변화도를 초기화합니다. net에 inputs를 전달하여 outputs를 계산합니다. criterion을 사용하여 outputs와 labels의 손실을 계산합니다. loss.backward()를 사용하여 역전파를 수행합니다. 마지막으로 optimizer.step()을 호출하여 최적화를 수행합니다.\n",
    "\n",
    "매 에폭마다 running loss를 계산하여 출력합니다. i % 2000 == 1999 조건문을 사용하여 매 2000 배치마다 running loss를 출력합니다.\n",
    "\n",
    "마지막으로, 학습이 완료되면 Finished Training을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46208faa",
   "metadata": {},
   "source": [
    "## 테스트 데이터 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0984312",
   "metadata": {},
   "source": [
    "테스트 데이터셋을 사용하여 학습된 모델의 성능을 평가합니다. torch.no_grad()를 사용하여 추론 단계에서의 변화도 계산을 방지합니다. testloader에서 배치를 하나씩 가져옵니다. net에 images를 전달하여 outputs를 계산합니다. torch.max()를 사용하여 outputs에서 각 샘플별로 최대값을 가지는 인덱스를 가져옵니다. 이를 통해 예측된 라벨 predicted를 구합니다.\n",
    "\n",
    "예측된 라벨 predicted와 실제 라벨 labels를 비교하여 올바르게 예측된 샘플의 개수를 correct에 누적합니다. 모든 샘플의 개수는 total에 누적합니다. 마지막으로, 전체 샘플 중에서 올바르게 예측한 샘플의 비율인 정확도를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8973",
   "metadata": {},
   "source": [
    "## 학습한 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa47de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './mnist_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977ba00",
   "metadata": {},
   "source": [
    "torch.save() 함수를 사용하여 모델의 state_dict를 파일에 저장합니다. state_dict는 모델의 학습 가능한 매개변수들을 포함합니다.\n",
    "\n",
    "이제 모델을 저장했으므로, 나중에 다시 불러와서 사용할 수 있습니다. 다음과 같이 저장된 모델을 불러와서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터셋 다운로드 및 전처리\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './mnist_net.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20442a",
   "metadata": {},
   "source": [
    "Net() 클래스로 빈 모델을 생성한 다음, load_state_dict() 메소드를 사용하여 저장된 state_dict를 불러와서 모델에 적용합니다. 이제 불러온 모델을 사용하여 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
